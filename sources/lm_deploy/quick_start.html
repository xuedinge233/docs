

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>快速开始 &mdash; 昇腾开源  文档</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=ec38875e" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=7d86a446"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=f281be69"></script>
      <script src="../../_static/package_info.js?v=2b3ed588"></script>
      <script src="../../_static/statistics.js?v=ed8c2343"></script>
      <script src="../../_static/translations.js?v=beaddf03"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="Torchchat" href="../torchchat/index.html" />
    <link rel="prev" title="安装指南" href="install.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            昇腾开源
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="搜索文档" aria-label="搜索文档" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="导航菜单">
              <p class="caption" role="heading"><span class="caption-text">开始使用</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../ascend/quick_install.html">快速安装昇腾环境</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">原生支持的AI项目</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../pytorch/index.html">PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../llamafactory/index.html">LLaMA-Factory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../accelerate/index.html">Accelerate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../transformers/index.html">Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deepspeed/index.html">DeepSpeed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnxruntime/index.html">ONNX Runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="../open_clip/index.html">open_clip</a></li>
<li class="toctree-l1"><a class="reference internal" href="../timm/index.html">timm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Diffusers/index.html">Diffusers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../opencv/index.html">OpenCV</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sd_webui/index.html">Stable-Diffusion-WebUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lm_evaluation/index.html">LM-Evalution-Harness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../wenet/index.html">WeNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../whisper_cpp/index.html">Whisper.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../llama_cpp/index.html">Llama.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sentence_transformers/index.html">Sentence Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../trl/index.html">Transformer Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../opencompass/index.html">OpenCompass</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">LMDeploy</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="install.html">安装指南</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">快速开始</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id3">安装</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id4">环境准备</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#drivers-firmware-cann">Drivers，Firmware 和 CANN</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id8">构建镜像</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id10">离线批处理</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#llm">LLM 推理</a></li>
<li class="toctree-l4"><a class="reference internal" href="#vlm">VLM 推理</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id11">在线服务</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id12">LLM 模型服务</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id13">VLM 模型服务</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id14">使用命令行与LLM模型对话</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id15">量化</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../torchchat/index.html">Torchchat</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torchtitan/index.html">TorchTitan</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="移动版导航菜单" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">昇腾开源</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="页面导航">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">LMDeploy</a></li>
      <li class="breadcrumb-item active">快速开始</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/sources/lm_deploy/quick_start.rst.txt" rel="nofollow"> 查看页面源码</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="id1">
<h1>快速开始<a class="headerlink" href="#id1" title="Link to this heading"></a></h1>
<p>我们基于 LMDeploy 的 PytorchEngine，增加了华为昇腾设备（Atlas 800T A2）的支持。所以，在华为昇腾上使用 LMDeploy 的方法与在英伟达 GPU 上使用 PytorchEngine 后端的方法几乎相同。在阅读本教程之前，请先阅读原版的 <a class="reference external" href="https://github.com/InternLM/lmdeploy/blob/main/docs/zh_cn/get_started/get_started.md">快速开始</a> 。</p>
<section id="id3">
<h2>安装<a class="headerlink" href="#id3" title="Link to this heading"></a></h2>
<p>我们强烈建议用户构建一个 Docker 镜像以简化环境设置。
克隆 lmdeploy 的源代码，Dockerfile 位于 docker 目录中。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/InternLM/lmdeploy.git
<span class="linenos">2</span><span class="nb">cd</span><span class="w"> </span>lmdeploy
</pre></div>
</div>
</section>
<section id="id4">
<h2>环境准备<a class="headerlink" href="#id4" title="Link to this heading"></a></h2>
<p>Docker 版本应不低于 18.03。并且需按照 <a class="reference external" href="https://www.hiascend.com/document/detail/zh/mindx-dl/60rc2/clusterscheduling/clusterschedulingig/clusterschedulingig/dlug_installation_012.html">官方指南</a> 安装 Ascend Docker Runtime。</p>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>如果在后续容器内出现 <cite>libascend_hal.so: cannot open shared object file</cite> 错误，说明 Ascend Docker Runtime 没有被正确安装。</p>
</div>
<section id="drivers-firmware-cann">
<h3>Drivers，Firmware 和 CANN<a class="headerlink" href="#drivers-firmware-cann" title="Link to this heading"></a></h3>
<p>目标机器需安装华为驱动程序和固件版本至少为 23.0.3，请参考
<a class="reference external" href="https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/800alpha001/softwareinst/instg/instg_0005.html">CANN 驱动程序和固件安装</a>
和 <a class="reference external" href="https://www.hiascend.com/hardware/firmware-drivers/community?product=4&amp;model=26&amp;cann=8.0.RC2.beta1&amp;driver=1.0.25.alpha">下载资源</a> 。</p>
<p>另外，<strong>docker/Dockerfile_aarch64_ascend</strong> 没有提供CANN 安装包，用户需要自己从 <a class="reference external" href="https://www.hiascend.com/developer/download/community/result?module=cann&amp;cann=8.0.RC2.beta1&amp;product=4&amp;model=26">昇腾资源下载中心</a> 下载 CANN（version 8.0.RC2.beta1）软件包。
并将 <strong>Ascend-cann-kernels-910b*.run</strong> ，<strong>Ascend-cann-nnal_*.run</strong> 和 <strong>Ascend-cann-toolkit*.run</strong> 放在 lmdeploy 源码根目录下。</p>
</section>
<section id="id8">
<h3>构建镜像<a class="headerlink" href="#id8" title="Link to this heading"></a></h3>
<p>请在 lmdeploy 源代码根目录下执行以下镜像构建命令，CANN 相关的安装包也放在此目录下。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="nv">DOCKER_BUILDKIT</span><span class="o">=</span><span class="m">1</span><span class="w"> </span>docker<span class="w"> </span>build<span class="w"> </span>-t<span class="w"> </span>lmdeploy-aarch64-ascend:latest<span class="w"> </span><span class="se">\</span>
<span class="linenos">2</span>-f<span class="w"> </span>docker/Dockerfile_aarch64_ascend<span class="w"> </span>.
</pre></div>
</div>
<p>如果以下命令执行没有任何错误，这表明环境设置成功。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span>docker<span class="w"> </span>run<span class="w"> </span>-e<span class="w"> </span><span class="nv">ASCEND_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span>--rm<span class="w"> </span>--name<span class="w"> </span>lmdeploy<span class="w"> </span>-t<span class="w"> </span>lmdeploy-aarch64-ascend:latest<span class="w"> </span>lmdeploy<span class="w"> </span>check_env
</pre></div>
</div>
<p>关于在昇腾设备上运行 <cite>docker run</cite> 命令的详情，请参考这篇 <a class="reference external" href="https://www.hiascend.com/document/detail/zh/mindx-dl/60rc1/clusterscheduling/dockerruntimeug/dlruntime_ug_013.html">文档</a> 。</p>
</section>
</section>
<section id="id10">
<h2>离线批处理<a class="headerlink" href="#id10" title="Link to this heading"></a></h2>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>图模式已经支持了 Atlas 800T A2。目前，单卡下的 LLaMa3-8B/LLaMa2-7B/Qwen2-7B 已经通过测试。用户可以设定 <cite>eager_mode=False</cite> 来开启图模式，或者设定 <cite>eager_mode=True</cite> 来关闭图模式。(启动图模式需要事先 source <cite>/usr/local/Ascend/nnal/atb/set_env.sh</cite>)</p>
</div>
<section id="llm">
<h3>LLM 推理<a class="headerlink" href="#llm" title="Link to this heading"></a></h3>
<p>将 <cite>device_type=&quot;ascend&quot;</cite> 加入 <cite>PytorchEngineConfig</cite> 的参数中。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="kn">from</span><span class="w"> </span><span class="nn">lmdeploy</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span>
<span class="linenos">2</span><span class="kn">from</span><span class="w"> </span><span class="nn">lmdeploy</span><span class="w"> </span><span class="kn">import</span> <span class="n">PytorchEngineConfig</span>
<span class="linenos">3</span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
<span class="linenos">4</span>    <span class="n">pipe</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;internlm/internlm2_5-7b-chat&quot;</span><span class="p">,</span>
<span class="linenos">5</span>                    <span class="n">backend_config</span><span class="o">=</span><span class="n">PytorchEngineConfig</span><span class="p">(</span><span class="n">tp</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">device_type</span><span class="o">=</span><span class="s2">&quot;ascend&quot;</span><span class="p">,</span> <span class="n">eager_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="linenos">6</span>    <span class="n">question</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Shanghai is&quot;</span><span class="p">,</span> <span class="s2">&quot;Please introduce China&quot;</span><span class="p">,</span> <span class="s2">&quot;How are you?&quot;</span><span class="p">]</span>
<span class="linenos">7</span>    <span class="n">response</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span><span class="n">question</span><span class="p">)</span>
<span class="linenos">8</span>    <span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="vlm">
<h3>VLM 推理<a class="headerlink" href="#vlm" title="Link to this heading"></a></h3>
<p>将 <cite>device_type=&quot;ascend&quot;</cite> 加入 <cite>PytorchEngineConfig</cite> 的参数中。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="kn">from</span><span class="w"> </span><span class="nn">lmdeploy</span><span class="w"> </span><span class="kn">import</span> <span class="n">pipeline</span><span class="p">,</span> <span class="n">PytorchEngineConfig</span>
<span class="linenos">2</span><span class="kn">from</span><span class="w"> </span><span class="nn">lmdeploy.vl</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_image</span>
<span class="linenos">3</span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
<span class="linenos">4</span>    <span class="n">pipe</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s1">&#39;OpenGVLab/InternVL2-2B&#39;</span><span class="p">,</span>
<span class="linenos">5</span>                    <span class="n">backend_config</span><span class="o">=</span><span class="n">PytorchEngineConfig</span><span class="p">(</span><span class="n">tp</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">device_type</span><span class="o">=</span><span class="s1">&#39;ascend&#39;</span><span class="p">,</span> <span class="n">eager_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="linenos">6</span>    <span class="n">image</span> <span class="o">=</span> <span class="n">load_image</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/open-mmlab/mmdeploy/main/tests/data/tiger.jpeg&#39;</span><span class="p">)</span>
<span class="linenos">7</span>    <span class="n">response</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">((</span><span class="s1">&#39;describe this image&#39;</span><span class="p">,</span> <span class="n">image</span><span class="p">))</span>
<span class="linenos">8</span>    <span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="id11">
<h2>在线服务<a class="headerlink" href="#id11" title="Link to this heading"></a></h2>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>图模式已经支持 Atlas 800T A2。目前，单卡下的 InternLM2-7B/LLaMa2-7B/Qwen2-7B 已经通过测试。
在线服务时，图模式默认开启，用户可以添加 <cite>--eager-mode</cite> 来关闭图模式。(启动图模式需要事先 source <cite>/usr/local/Ascend/nnal/atb/set_env.sh</cite> )</p>
</div>
<section id="id12">
<h3>LLM 模型服务<a class="headerlink" href="#id12" title="Link to this heading"></a></h3>
<p>将 <cite>--device ascend</cite> 加入到服务启动命令中。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span>lmdeploy<span class="w"> </span>serve<span class="w"> </span>api_server<span class="w"> </span>--backend<span class="w"> </span>pytorch<span class="w"> </span>--device<span class="w"> </span>ascend<span class="w"> </span>--eager-mode<span class="w"> </span>internlm/internlm2_5-7b-chat
</pre></div>
</div>
</section>
<section id="id13">
<h3>VLM 模型服务<a class="headerlink" href="#id13" title="Link to this heading"></a></h3>
<p>将 <cite>--device ascend</cite> 加入到服务启动命令中。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span>lmdeploy<span class="w"> </span>serve<span class="w"> </span>api_server<span class="w"> </span>--backend<span class="w"> </span>pytorch<span class="w"> </span>--device<span class="w"> </span>ascend<span class="w"> </span>--eager-mode<span class="w"> </span>OpenGVLab/InternVL2-2B
</pre></div>
</div>
</section>
</section>
<section id="id14">
<h2>使用命令行与LLM模型对话<a class="headerlink" href="#id14" title="Link to this heading"></a></h2>
<p>将 <cite>--device ascend</cite> 加入到服务启动命令中。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span>lmdeploy<span class="w"> </span>chat<span class="w"> </span>internlm/internlm2_5-7b-chat<span class="w"> </span>--backend<span class="w"> </span>pytorch<span class="w"> </span>--device<span class="w"> </span>ascend<span class="w"> </span>--eager-mode
</pre></div>
</div>
<p>也可以运行以下命令使启动容器后开启 lmdeploy 聊天</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span>docker<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>-it<span class="w"> </span>lmdeploy_ascend_demo<span class="w"> </span><span class="se">\</span>
<span class="linenos">2</span>bash<span class="w"> </span>-i<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;lmdeploy chat --backend pytorch --device ascend --eager-mode internlm/internlm2_5-7b-chat&quot;</span>
</pre></div>
</div>
</section>
<section id="id15">
<h2>量化<a class="headerlink" href="#id15" title="Link to this heading"></a></h2>
<p>运行下面的代码可以在 Atlas 800T A2 上对权重进行 W4A16 量化。</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span>lmdeploy<span class="w"> </span>lite<span class="w"> </span>auto_awq<span class="w"> </span><span class="nv">$HF_MODEL</span><span class="w"> </span>--work-dir<span class="w"> </span><span class="nv">$WORK_DIR</span><span class="w"> </span>--device<span class="w"> </span>npu
</pre></div>
</div>
<p>支持的模型列表请参考 <a class="reference external" href="https://github.com/InternLM/lmdeploy/blob/main/docs/zh_cn/supported_models/supported_models.md">支持的模型</a> 。</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="页脚">
        <a href="install.html" class="btn btn-neutral float-left" title="安装指南" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> 上一页</a>
        <a href="../torchchat/index.html" class="btn btn-neutral float-right" title="Torchchat" accesskey="n" rel="next">下一页 <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; 版权所有 2024, Ascend。</p>
  </div>

  利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用的 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    由 <a href="https://readthedocs.org">Read the Docs</a> 开发.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>